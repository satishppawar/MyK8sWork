# Day Three - Deploy Initial Workloads

---

In this section we will deploy some initial workloads into our cluster.  

---

## Helm

The first thing we need to deploy is _Helm_.  The way we will install it is not the most secure way but it is fine for what we are doing with this course. A more secure install is shown [here](https://docs.helm.sh/using_helm/#using-ssl-between-helm-and-tiller).  But we will use [this](https://docs.helm.sh/using_helm/#example-service-account-with-cluster-admin-role).

We start off by creating a _ServiceAccount_ for `tiller`, the server side component of _Helm_.

```console
kubectl create serviceaccount tiller --namespace kube-system
```

Then we create a file with a _ClusterRoleBinding_ for the _ServiceAccount_ that gives it admin access to the cluster.  Of course this is not recommended in a production system.  _Helm_ provides a number of more secure options for how it is deployed.  

```console
vi ~/tmp/rbac-config.yaml
```

Add the following to the file we just created.

```console
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
```

Now add the _ClusterRoleBinding_ to the cluster.

```console
kubectl create -f ~/tmp/rbac-config.yaml
```

And, finally deploy _Tiller_ with an argument that defines the _ServiceAccount_ it will use.

```console
helm init --service-account tiller
```

The check that `tiller` has been deployed.

```console
helm version
```


## Ingress Controller

Next up is an _Ingress Controller_ that makes available outside the cluster the workloads with an _Ingress_ resource.  We will use the standard _Nginx Ingress Controller_.  The _Helm Chart_ can be found [here](https://github.com/kubernetes/charts/tree/master/stable/nginx-ingress).

Let's look at all the available versions of the _Nginx Ingress Controller_.

```console
helm search stable/nginx-ingress -l
```

The version we will use is `0.22.1` and we will install it in an `ingress` namespace.  We are also overriding some the default values so that we can access the _Ingress Controller_ using the standard ports, 80 and 443, on each of the worker nodes.

```console
helm upgrade --install nginx-ingress \
  --namespace ingress \
  --set controller.kind=DaemonSet \
  --set controller.daemonset.useHostPort=true \
  --version 0.22.1 \
  stable/nginx-ingress
```

Let's watch it come up.

```console
kubectl -n ingress get pod -w
```

Then we can test that we can access the _Ingress Controller_.

```console
curl http://192.168.26.11
```

We should see the default backend.

```console
default backend - 404
```


## Heapster

We then want to install _Heapster_ as it is used the the _Kubernetes_ dashboard to collect metrics from the nodes and the _Pods_.  The _Helm Chart_ can be found [here](https://github.com/kubernetes/charts/tree/master/stable/heapster).

```console
helm upgrade --install heapster \
  --namespace kube-system \
  --version 0.3.0 \
  stable/heapster
```

And, let's check it is running.

```console
kubectl -n kube-system get pod -l app=heapster-heapster
```


## Dashboard

Finally, let's install the _Kubernetes_ dashboard.  The _Helm Chart_ can be found [here](https://github.com/kubernetes/charts/tree/master/stable/kubernetes-dashboard).

Now, we did actually get an install of the dashboard when we installed our cluster.  However, we want to use the _Helm Chart_ version as we will be customising it later.  So let's go ahead and remove the default dashboard.

```console
kubectl -n kube-system delete deployment kubernetes-dashboard
kubectl -n kube-system delete service kubernetes-dashboard
kubectl -n kube-system delete sa kubernetes-dashboard
```

And now we can install the _Helm Chart_ version.

```console
helm upgrade --install kubernetes-dashboard \
  --namespace kube-system \
  --set rbac.clusterAdminRole=true \
  --version 0.7.1 \
  stable/kubernetes-dashboard
```

**Note**

The `rbac.clusterAdminRole` argument is not recommended in a production cluster.

In the output from _Helm_ we will be given details of how we can access the dashboard.  We will make it easier to access the dashboard in a later part of the course.

```console
export POD_NAME=$(kubectl get pods -n kube-system -l "app=kubernetes-dashboard,release=kubernetes-dashboard" -o jsonpath="{.items[0].metadata.name}")
kubectl -n kube-system port-forward $POD_NAME 8443:8443
```

We've setup a port forward to the dashboard _Pod_ that is listening on `https://127.0.0.1:8443`.  So let's go ahead and access the dashboard.

It's likely that we will be told that the connection is not private.  This is because the TLS certificate is invalid.  This is also something we will fix later on in the course.  Go ahead and tell your browser to trust the certificate.

When we are preseneted with a screen asking for either a `kubconfig` file or a token to authenticate, just click the _Skip_ button.  We will now be at our dashboard.


## Finally

Let's check our deployed _Helm Charts_.

```console
helm ls
```

What we have done in this section is deploy some initial workloads into our cluster.

# Next

In the next section we will revisit our `first-app` from earlier and this time enable it with an _Ingress_ resource.

[Next](03-05.md)

