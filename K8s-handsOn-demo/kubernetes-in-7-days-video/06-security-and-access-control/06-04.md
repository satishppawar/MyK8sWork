# Day Six - Configuring Kubernetes to use OIDC

---

In this section we will configure our _Kubernetes_ cluster so that it is able to use _Keycloak_ to authenticate users.

---

There are a couple of things that we will need to do on the _Kubernetes_ master node.

* Copy over the `ca.crt` root certificate that we generated in the last section.
* Change the arguments to the container for the `kube-apiserver`.

We will use _Vagrant_ to login to the master node, as already demonstrated [here](../03-building-a-complex-cluster/03-03.md).

```console
# This is the location that you cloned the k8s-vagrant-multi-node repo into
cd ~/Sites/ThirdParty/k8s-vagrant-multi-node

# SSH into the master node
vagrant ssh

# Switch to the root user
sudo su -

# Paste in the contents of the Root CA certificate that was previously generated with onessl
vi /etc/ssl/certs/ca.crt

# Enter the location that the kubelet looks for static Pod definitions
cd /etc/kubernetes/manifests/

# Backup the manifest file for the kube-apiserver.  You know, just in case!
cp kube-apiserver.yaml kube-apiserver.yaml.backup

$ Edit the manifest file for the kube-apiserver
vi kube-apiserver.yaml
```

Now that you have the manifest file for the `kube-apiserver` open you will need to add a new set of arguments to the container `command`.  Locate the following section in the manifest file.

```yaml
spec:
  containers:
  - command:
    - kube-apiserver
```

At the end of this section block add the following new arguments.

```yaml
    - --oidc-issuer-url=https://keycloak.192.168.26.11.nip.io/auth/realms/kube7days
    - --oidc-username-claim=preferred_username
    - --oidc-username-prefix=-
    - --oidc-groups-claim=groups
    - --oidc-client-id=kubernetes
    - --oidc-ca-file=/etc/ssl/certs/ca.crt
```

Once you save the file the `kubelet` will detect that the manifest has changed and it will restart the `kube-apiserver` _Pod_.  This means that there will be a short outage for the API Server.  However, all the running workloads will continue to run.

Back to your usual terminal, not inside the master node, you can check the status of the `kube-apiserver` _Pod_.

```console
kubectl -n kube-system get pod -l component=kube-apiserver
```

```console
NAME                    READY     STATUS    RESTARTS   AGE
kube-apiserver-master   1/1       Running   0          1m
```

We have now laid the foundation blocks for the next two sections, where we secure both the _Kubernetes_ dashboard and the `kubectl` command.


What we have done in this section is reconfigure our _Kubernetes_ cluster so that it can confirm a user token has been signed by our _Keycloak_ server.


# Next

In the next section we will secure the _Kubernetes_ dashboard.

[Next](06-05.md)
